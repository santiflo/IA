{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 2: Aprendizaje de maquina sobre el censo de 1994"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Santiago Florian Bustamante_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "El siguiente taller es con el fin de evaluar el desempeño de algunas de las técnicas aprendizaje automático vistas en clase sobre un mismo conjunto de datos. Esto es con el fin de evaluar el desempeño producido por los métodos de aprendizaje implementados y aplicar un criterio sobre cual método tiene mejor resultado sobre la tarea a resolver.\n",
    "\n",
    "\n",
    "## Definición de la tarea\n",
    "El conjunto de datos en el que se va a trabajara es una base de datos de 1994 brindada por UCI Maching Learning Repository abierta al público desde 1996 llamada \"adult”. La cual cuenta con la cantidad de 48842 instancias divididas en 14 atributos con valores mixtos; continuos y discretos. La tarea de clasificación es determinar si una persona gana menos de 50k o más de 50k.\n",
    "\n",
    "los 14 atributos son los siguientes:\n",
    "* age(0): continuous.\n",
    "\n",
    "* workclass(1): Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "\n",
    "* fnlwgt(2): continuous.\n",
    "\n",
    "* education(3): Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "\n",
    "* education-num(4): continuous.\n",
    "\n",
    "* marital-status(5): Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "\n",
    "* occupation(6): Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "\n",
    "* relationship(7): Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "\n",
    "* race(8): White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "\n",
    "* sex(9): Female, Male.\n",
    "\n",
    "* capital-gain(10): continuous.\n",
    "\n",
    "* capital-loss(11): continuous.\n",
    "\n",
    "* hours-per-week(12): continuous.\n",
    "\n",
    "* native-country(13): United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "El 15 valor en los datos equivale a  >50K, <=50K, que respectivamente indica cuando una persona gana 50k más o cuando gana menos de 50k.\n",
    "\n",
    "## Preparar la información\n",
    "### Cargar la información\n",
    "\n",
    "Haciendo uso de la librería pandas, se pueden cargar los archivos \"adult.data\" y \"adult.test\" los cuales contienen todos los datos usados para el desarrollo del taller. El documento \"adult.data\" contiene 32561 instancias y el documento \"adult.test\" contiene 16281 instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15) (16281, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32556</td>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32557</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32558</td>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32559</td>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32560</td>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                  1       2            3   4                    5   \\\n",
       "0      39          State-gov   77516    Bachelors  13        Never-married   \n",
       "1      50   Self-emp-not-inc   83311    Bachelors  13   Married-civ-spouse   \n",
       "2      38            Private  215646      HS-grad   9             Divorced   \n",
       "3      53            Private  234721         11th   7   Married-civ-spouse   \n",
       "4      28            Private  338409    Bachelors  13   Married-civ-spouse   \n",
       "...    ..                ...     ...          ...  ..                  ...   \n",
       "32556  27            Private  257302   Assoc-acdm  12   Married-civ-spouse   \n",
       "32557  40            Private  154374      HS-grad   9   Married-civ-spouse   \n",
       "32558  58            Private  151910      HS-grad   9              Widowed   \n",
       "32559  22            Private  201490      HS-grad   9        Never-married   \n",
       "32560  52       Self-emp-inc  287927      HS-grad   9   Married-civ-spouse   \n",
       "\n",
       "                       6               7       8        9      10  11  12  \\\n",
       "0            Adm-clerical   Not-in-family   White     Male   2174   0  40   \n",
       "1         Exec-managerial         Husband   White     Male      0   0  13   \n",
       "2       Handlers-cleaners   Not-in-family   White     Male      0   0  40   \n",
       "3       Handlers-cleaners         Husband   Black     Male      0   0  40   \n",
       "4          Prof-specialty            Wife   Black   Female      0   0  40   \n",
       "...                   ...             ...     ...      ...    ...  ..  ..   \n",
       "32556        Tech-support            Wife   White   Female      0   0  38   \n",
       "32557   Machine-op-inspct         Husband   White     Male      0   0  40   \n",
       "32558        Adm-clerical       Unmarried   White   Female      0   0  40   \n",
       "32559        Adm-clerical       Own-child   White     Male      0   0  20   \n",
       "32560     Exec-managerial            Wife   White   Female  15024   0  40   \n",
       "\n",
       "                   13      14  \n",
       "0       United-States   <=50K  \n",
       "1       United-States   <=50K  \n",
       "2       United-States   <=50K  \n",
       "3       United-States   <=50K  \n",
       "4                Cuba   <=50K  \n",
       "...               ...     ...  \n",
       "32556   United-States   <=50K  \n",
       "32557   United-States    >50K  \n",
       "32558   United-States   <=50K  \n",
       "32559   United-States   <=50K  \n",
       "32560   United-States    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Pandas es una libreria que ofrece estructuras de datos y operaciones para manipular tablas numéricas y series temporales.\n",
    "import pandas as pd\n",
    "#LabelEncoder: Libreria que permite dividir el conjunto de datos en subconjuntos\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#train_test_split: Libreria que permite dividir el conjunto de datos en subconjuntos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#Leer la informacion del archivo de datos para entrenamiento\n",
    "train = pd.read_csv(\"adult.data\",header=None, na_values=[' ?'])\n",
    "test = pd.read_csv(\"adult.test\",header=None, na_values=[' ?'])\n",
    "\n",
    "#*.shape permite saber la dimension del objeto\n",
    "print(train.shape,test.shape)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de la información\n",
    "La base de datos \"adult\", es una base de datos bastante completa lo cual la hace perfecta para practicar las técnicas de aprendizaje, aun así, algunas instancias serán eliminadas debido a que no presentan valores en algunos de sus atributos. Lo cual deja al conjunto de entrenamiento con un total de 30162 instancias y para el conjunto de testing 15060.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 15) (15060, 15)\n"
     ]
    }
   ],
   "source": [
    "#*.dropna(inplace=True): Mantenga el DataFrame con entradas válidas en la misma variable.\n",
    "train.dropna(inplace=True)\n",
    "test.dropna(inplace=True)\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de haber eliminado los datos faltantes es necesario transofrmar los valores categoricos a valores numericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoder: transforma los atributos categoricos a numericos\n",
    "train[1]= LabelEncoder().fit_transform(train[1])   #workclass\n",
    "train[3]= LabelEncoder().fit_transform(train[3])   #education\n",
    "train[5]= LabelEncoder().fit_transform(train[5])   #marital-status\n",
    "train[6]= LabelEncoder().fit_transform(train[6])   #occupation\n",
    "train[7]= LabelEncoder().fit_transform(train[7])   #relationship\n",
    "train[8]= LabelEncoder().fit_transform(train[8])   #race\n",
    "train[9]= LabelEncoder().fit_transform(train[9])   #sex\n",
    "train[13]= LabelEncoder().fit_transform(train[13]) #native-contry\n",
    "train[14]= LabelEncoder().fit_transform(train[14]) #el dinero que gana actualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test[1]= LabelEncoder().fit_transform(test[1])    #workclass\n",
    "test[3]= LabelEncoder().fit_transform(test[3])    #education\n",
    "test[5]= LabelEncoder().fit_transform(test[5])    #marital-status\n",
    "test[6]= LabelEncoder().fit_transform(test[6])    #occupation\n",
    "test[7]= LabelEncoder().fit_transform(test[7])    #relationship\n",
    "test[8]= LabelEncoder().fit_transform(test[8])    #race\n",
    "test[9]= LabelEncoder().fit_transform(test[9])    #sex\n",
    "test[13]= LabelEncoder().fit_transform(test[13])  #native-contry\n",
    "test[14]= LabelEncoder().fit_transform(test[14])  #el dinero que gana actualmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se va identificar los datos atípicos de los atributos continuos. Los datos atípicos que sean encontrados su valor serán remplazados por la media del atributo.\n",
    "\n",
    "La media equivale u una medida de tendencia central y desviacion estandar a una medidad de dispercion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         38.437902\n",
      "1          2.199324\n",
      "2     189793.833930\n",
      "3         10.333764\n",
      "4         10.121312\n",
      "5          2.580134\n",
      "6          5.959850\n",
      "7          1.418341\n",
      "8          3.678602\n",
      "9          0.675685\n",
      "10      1092.007858\n",
      "11        88.372489\n",
      "12        40.931238\n",
      "13        36.382567\n",
      "14         0.248922\n",
      "dtype: float64\n",
      "0         13.134665\n",
      "1          0.953925\n",
      "2     105652.971529\n",
      "3          3.812292\n",
      "4          2.549995\n",
      "5          1.498016\n",
      "6          4.029566\n",
      "7          1.601338\n",
      "8          0.834709\n",
      "9          0.468126\n",
      "10      7406.346497\n",
      "11       404.298370\n",
      "12        11.979984\n",
      "13         6.105372\n",
      "14         0.432396\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "media=train.mean() #Media de cada atributo\n",
    "std= train.std() # desviación de cada atributo\n",
    "print(media)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos atípicos serán identificados sobre 3 desviaciones de la media. Se encontraron 2411 datos atípicos al utilizar 3 desviaciones estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = [0,2,4,10,11,12] #Atributos continuos: age, fnlwgt, education-num, capital-gain, capital-loss, hours-per-week\n",
    "cnt = 0\n",
    "for i in att:\n",
    "    for j in range(len(train[i])):\n",
    "        try:\n",
    "            if(train[i][j]>media[i]+3*std[i]):\n",
    "                train[i][j]=media[i]\n",
    "                cnt = cnt+1\n",
    "            elif(train[i][j]<media[i]-3*std[i]):\n",
    "                train[i][j]=media[i]\n",
    "                cnt =cnt+1\n",
    "        except: continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Coeficiente de Correlación es un valor cuantitativo de la relación entre dos o más variables. El coeficiente de correlación puede variar desde -1.00 hasta 1.00. La correlación de proporcionalidad directa o positiva se establece con los valores +1.00 y de proporcionalidad inversa o negativa, con -1.00. No existe relación entre las variables cuando el coeficiente es de 0.00.\n",
    "\n",
    "Al aplicar el coeficiente de coeficiente de correlación en los datos se puede identificar que no existe correlación alguna entre los atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078883</td>\n",
       "      <td>0.073748</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.056588</td>\n",
       "      <td>0.290154</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.248811</td>\n",
       "      <td>0.023726</td>\n",
       "      <td>0.083199</td>\n",
       "      <td>0.105178</td>\n",
       "      <td>0.034169</td>\n",
       "      <td>0.120187</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.248910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.078883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029983</td>\n",
       "      <td>0.017855</td>\n",
       "      <td>0.037233</td>\n",
       "      <td>0.034241</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.067417</td>\n",
       "      <td>0.044731</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>0.018044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.073748</td>\n",
       "      <td>0.029983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.035581</td>\n",
       "      <td>0.031942</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>0.025967</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.066991</td>\n",
       "      <td>0.009357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.017855</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.332256</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.038212</td>\n",
       "      <td>0.012717</td>\n",
       "      <td>0.011154</td>\n",
       "      <td>0.027888</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.063019</td>\n",
       "      <td>0.078790</td>\n",
       "      <td>0.078987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.056588</td>\n",
       "      <td>0.037233</td>\n",
       "      <td>0.035581</td>\n",
       "      <td>0.332256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058239</td>\n",
       "      <td>0.090053</td>\n",
       "      <td>0.096566</td>\n",
       "      <td>0.031790</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.127463</td>\n",
       "      <td>0.032850</td>\n",
       "      <td>0.162857</td>\n",
       "      <td>0.058860</td>\n",
       "      <td>0.336678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.290154</td>\n",
       "      <td>0.034241</td>\n",
       "      <td>0.031942</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.058239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022655</td>\n",
       "      <td>0.177964</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.119813</td>\n",
       "      <td>0.052686</td>\n",
       "      <td>0.025287</td>\n",
       "      <td>0.195004</td>\n",
       "      <td>0.025902</td>\n",
       "      <td>0.193518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.038212</td>\n",
       "      <td>0.090053</td>\n",
       "      <td>0.022655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053727</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.062313</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.051577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.248811</td>\n",
       "      <td>0.067417</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.012717</td>\n",
       "      <td>0.096566</td>\n",
       "      <td>0.177964</td>\n",
       "      <td>0.053727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>0.584876</td>\n",
       "      <td>0.074709</td>\n",
       "      <td>0.023259</td>\n",
       "      <td>0.266944</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.251003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.023726</td>\n",
       "      <td>0.044731</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>0.011154</td>\n",
       "      <td>0.031790</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089186</td>\n",
       "      <td>0.017989</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.052003</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>0.071658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083199</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>0.025967</td>\n",
       "      <td>0.027888</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.119813</td>\n",
       "      <td>0.062313</td>\n",
       "      <td>0.584876</td>\n",
       "      <td>0.089186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062121</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.235553</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.216699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.105178</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>0.127463</td>\n",
       "      <td>0.052686</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.074709</td>\n",
       "      <td>0.017989</td>\n",
       "      <td>0.062121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020478</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.011003</td>\n",
       "      <td>0.275481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.034169</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.032850</td>\n",
       "      <td>0.025287</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.023259</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.020478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025248</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.066608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.120187</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.063019</td>\n",
       "      <td>0.162857</td>\n",
       "      <td>0.195004</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.266944</td>\n",
       "      <td>0.052003</td>\n",
       "      <td>0.235553</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.025248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>0.241097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>0.066991</td>\n",
       "      <td>0.078790</td>\n",
       "      <td>0.058860</td>\n",
       "      <td>0.025902</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.011003</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.248910</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>0.078987</td>\n",
       "      <td>0.336678</td>\n",
       "      <td>0.193518</td>\n",
       "      <td>0.051577</td>\n",
       "      <td>0.251003</td>\n",
       "      <td>0.071658</td>\n",
       "      <td>0.216699</td>\n",
       "      <td>0.275481</td>\n",
       "      <td>0.066608</td>\n",
       "      <td>0.241097</td>\n",
       "      <td>0.023268</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   1.000000  0.078883  0.073748  0.001921  0.056588  0.290154  0.005466   \n",
       "1   0.078883  1.000000  0.029983  0.017855  0.037233  0.034241  0.015572   \n",
       "2   0.073748  0.029983  1.000000  0.026697  0.035581  0.031942  0.002003   \n",
       "3   0.001921  0.017855  0.026697  1.000000  0.332256  0.040664  0.038212   \n",
       "4   0.056588  0.037233  0.035581  0.332256  1.000000  0.058239  0.090053   \n",
       "5   0.290154  0.034241  0.031942  0.040664  0.058239  1.000000  0.022655   \n",
       "6   0.005466  0.015572  0.002003  0.038212  0.090053  0.022655  1.000000   \n",
       "7   0.248811  0.067417  0.008034  0.012717  0.096566  0.177964  0.053727   \n",
       "8   0.023726  0.044731  0.013508  0.011154  0.031790  0.068627  0.000717   \n",
       "9   0.083199  0.074973  0.025967  0.027888  0.007680  0.119813  0.062313   \n",
       "10  0.105178  0.016168  0.004213  0.024792  0.127463  0.052686  0.008472   \n",
       "11  0.034169  0.001168  0.005314  0.009558  0.032850  0.025287  0.001774   \n",
       "12  0.120187  0.038067  0.018784  0.063019  0.162857  0.195004  0.009222   \n",
       "13  0.001237  0.007668  0.066991  0.078790  0.058860  0.025902  0.003483   \n",
       "14  0.248910  0.018044  0.009357  0.078987  0.336678  0.193518  0.051577   \n",
       "\n",
       "          7         8         9         10        11        12        13  \\\n",
       "0   0.248811  0.023726  0.083199  0.105178  0.034169  0.120187  0.001237   \n",
       "1   0.067417  0.044731  0.074973  0.016168  0.001168  0.038067  0.007668   \n",
       "2   0.008034  0.013508  0.025967  0.004213  0.005314  0.018784  0.066991   \n",
       "3   0.012717  0.011154  0.027888  0.024792  0.009558  0.063019  0.078790   \n",
       "4   0.096566  0.031790  0.007680  0.127463  0.032850  0.162857  0.058860   \n",
       "5   0.177964  0.068627  0.119813  0.052686  0.025287  0.195004  0.025902   \n",
       "6   0.053727  0.000717  0.062313  0.008472  0.001774  0.009222  0.003483   \n",
       "7   1.000000  0.117143  0.584876  0.074709  0.023259  0.266944  0.010809   \n",
       "8   0.117143  1.000000  0.089186  0.017989  0.008109  0.052003  0.124514   \n",
       "9   0.584876  0.089186  1.000000  0.062121  0.007943  0.235553  0.000618   \n",
       "10  0.074709  0.017989  0.062121  1.000000  0.020478  0.083770  0.011003   \n",
       "11  0.023259  0.008109  0.007943  0.020478  1.000000  0.025248  0.001223   \n",
       "12  0.266944  0.052003  0.235553  0.083770  0.025248  1.000000  0.006109   \n",
       "13  0.010809  0.124514  0.000618  0.011003  0.001223  0.006109  1.000000   \n",
       "14  0.251003  0.071658  0.216699  0.275481  0.066608  0.241097  0.023268   \n",
       "\n",
       "          14  \n",
       "0   0.248910  \n",
       "1   0.018044  \n",
       "2   0.009357  \n",
       "3   0.078987  \n",
       "4   0.336678  \n",
       "5   0.193518  \n",
       "6   0.051577  \n",
       "7   0.251003  \n",
       "8   0.071658  \n",
       "9   0.216699  \n",
       "10  0.275481  \n",
       "11  0.066608  \n",
       "12  0.241097  \n",
       "13  0.023268  \n",
       "14  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainCorr = train.corr()\n",
    "absTrainCorr = np.absolute(trainCorr)\n",
    "absTrainCorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que existe un desbalanceo ya que el conjunto 0 tiene el 75% de los datos, mientras que el conjunto 1 tiene el 25% restante de los datos. Esto puede generar un mejor aprendizaje para clasificar de manera correcta los datos pertenecientes al conjunto 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22654\n",
      "1     7508\n",
      "Name: 14, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.value_counts(train[14], sort = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de la información a conjuntos\n",
    "Ya que la base de datos ha sido adaptada para realizar el aprendizaje, se pueden dividir los conjuntos para entrenamiento, validación y testing. Debido a que la base de datos ya se encuentra presenta el conjunto de entrenamiento y testing, solo vamos a generar el conjunto de validación, el cual equivale al 10% de las instancias del conjunto de entrenamiento.\n",
    "Dejando de esta manera los conjuntos:\n",
    "* entrenamiento: 27145 instancias\n",
    "* validación: 3017 instancias\n",
    "* testing: 15060 instancias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento por validar:  (27145, 15)\n",
      "Conjunto de validacion:  (3017, 15)\n",
      "Conjunto de entrenamiento:  (30162, 15)\n",
      "Conjunto de testing:  (15060, 15)\n"
     ]
    }
   ],
   "source": [
    "train_t,validation = train_test_split(train, test_size=0.10)\n",
    "print(\"Conjunto de entrenamiento por validar: \",train_t.shape)\n",
    "print(\"Conjunto de validacion: \",validation.shape)\n",
    "print(\"Conjunto de entrenamiento: \", train.shape)\n",
    "print(\"Conjunto de testing: \", test.shape)\n",
    "\n",
    "#Separacion de los atributos de la clasificacion\n",
    "#Atributos training\n",
    "x_t = train_t.loc[:,:13]\n",
    "#Clasificacion training\n",
    "y_t = train_t.loc[:,14]\n",
    "\n",
    "#Atributos de validacion\n",
    "val_x = validation.loc[:,:13]\n",
    "#Clasificacion de validacion\n",
    "val_y = validation.loc[:,14]\n",
    "\n",
    "#Atributos de entrenamiento\n",
    "x = train.loc[:,:13]\n",
    "#Clasificacion de entrenamiento\n",
    "y = train.loc[:,14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión\n",
    "Ya habiendo dividido los conjuntos, se puede empezar a realizar el aprendizaje automático. La librería usada para realizar el entrenamiento se llama sklearn disponible para python2 y python 3. smv, se refiere a la máquina de vectores de soporte. Y tree, para los árboles de decisión.\n",
    "En un principio vamos a optimizar el rendimiento del árbol de decisiones realizando el entrenamiento en distintos arboles con distintos parámetros. Los parámetros que pueden ser modificados son:\n",
    "* **max_depth**: int o None, opcional (predeterminado = None) o Profundidad máxima de un árbol: la profundidad máxima del árbol. Si None, los nodos se expanden hasta que todas las hojas contengan menos de min_samples_split samples. El valor más alto de la profundidad máxima provoca un sobreajuste, y un valor más bajo provoca un ajuste insuficiente.\n",
    "* **splitter**: string, opcional (predeterminado = \"best\") o Estrategia dividida: este parámetro nos permite elegir la estrategia dividida. Las estrategias admitidas son \"best\" para elegir la mejor división y \"random\" para elegir la mejor división aleatoria.\n",
    "* **criterion**: opcional (predeterminado = \"gini\") o Elegir medida de selección de atributo: este parámetro nos permite utilizar la medida de selección de atributo diferente-diferente. Los criterios admitidos son \"gini\" para el índice de Gini y \"entropía\" para la ganancia de información.\n",
    "\n",
    "El criterio de usado evaluación para determinar el mejor resultado es accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidad del arbol: 1\n",
      "Arbol de decision con GINI y mejor division: 0.7543917799138217\n",
      "Arbol de decision con GINI y division aleatoria: 0.7543917799138217\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.7543917799138217\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.7543917799138217\n",
      "\n",
      "\n",
      "Profundidad del arbol: 2\n",
      "Arbol de decision con GINI y mejor division: 0.8256546237984753\n",
      "Arbol de decision con GINI y division aleatoria: 0.7543917799138217\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8137222406363938\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.7931720251905867\n",
      "\n",
      "\n",
      "Profundidad del arbol: 3\n",
      "Arbol de decision con GINI y mejor division: 0.8392442823997348\n",
      "Arbol de decision con GINI y division aleatoria: 0.814385150812065\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8389128273118992\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.7948293006297646\n",
      "\n",
      "\n",
      "Profundidad del arbol: 4\n",
      "Arbol de decision con GINI y mejor division: 0.8425588332780908\n",
      "Arbol de decision con GINI y division aleatoria: 0.8243288034471329\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8402386476632416\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.8230029830957906\n",
      "\n",
      "\n",
      "Profundidad del arbol: 5\n",
      "Arbol de decision con GINI y mejor division: 0.843221743453762\n",
      "Arbol de decision con GINI y division aleatoria: 0.7872058336095459\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8425588332780908\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.7842227378190255\n",
      "\n",
      "\n",
      "Profundidad del arbol: 6\n",
      "Arbol de decision con GINI y mejor division: 0.8415644680145841\n",
      "Arbol de decision con GINI y division aleatoria: 0.8263175339741465\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8415644680145841\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.8090818694066954\n",
      "\n",
      "\n",
      "Profundidad del arbol: 7\n",
      "Arbol de decision con GINI y mejor division: 0.8452104739807756\n",
      "Arbol de decision con GINI y division aleatoria: 0.8322837255551873\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8428902883659264\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.7901889294000662\n",
      "\n",
      "\n",
      "Profundidad del arbol: 8\n",
      "Arbol de decision con GINI y mejor division: 0.846536294332118\n",
      "Arbol de decision con GINI y division aleatoria: 0.8362611866092144\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8428902883659264\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.8359297315213788\n",
      "\n",
      "\n",
      "Profundidad del arbol: 9\n",
      "Arbol de decision con GINI y mejor division: 0.8468677494199536\n",
      "Arbol de decision con GINI y division aleatoria: 0.8273118992376532\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8475306595956248\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.8326151806430229\n",
      "\n",
      "\n",
      "Profundidad del arbol: 10\n",
      "Arbol de decision con GINI y mejor division: 0.8485250248591316\n",
      "Arbol de decision con GINI y division aleatoria: 0.834935366257872\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8409015578389128\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.8395757374875704\n",
      "\n",
      "\n",
      "Profundidad del arbol: 11\n",
      "Arbol de decision con GINI y mejor division: 0.8468677494199536\n",
      "Arbol de decision con GINI y division aleatoria: 0.839907192575406\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8442161087172688\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.8409015578389128\n",
      "\n",
      "\n",
      "Profundidad del arbol: 12\n",
      "Arbol de decision con GINI y mejor division: 0.8415644680145841\n",
      "Arbol de decision con GINI y division aleatoria: 0.8418959231024197\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8435531985415976\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.8322837255551873\n",
      "\n",
      "\n",
      "Profundidad del arbol: 13\n",
      "Arbol de decision con GINI y mejor division: 0.8418959231024197\n",
      "Arbol de decision con GINI y division aleatoria: 0.8495193901226383\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8455419290686113\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.8299635399403381\n",
      "\n",
      "\n",
      "Profundidad del arbol: 14\n",
      "Arbol de decision con GINI y mejor division: 0.8369240967848857\n",
      "Arbol de decision con GINI y division aleatoria: 0.8471992045077892\n",
      "Arbol de decision con Ganancia de informacion y mejor division: 0.8405701027510772\n",
      "Arbol de decision con Ganancia de informacion y division aleatoria: 0.8352668213457076\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_d = 15\n",
    "\n",
    "for i in range(1,m_d):\n",
    "    print(\"Profundidad del arbol: \"+str(i))\n",
    "    \n",
    "    #cfl_gini = arbol de desicion con metodo de ramificacion GINI y la mejor division\n",
    "        #max_dep = profundidad maxima del arbol\n",
    "    clf_gini = DecisionTreeClassifier(max_depth=i)\n",
    "    \n",
    "    #cfl_gini_rand = arbol de desicion con metodo de ramificacion GINI y usando division aleatoria\n",
    "        #max_dep = profundidad maxima del arbol\n",
    "        #splitter = estrategia de division\n",
    "    clf_gini_rand = DecisionTreeClassifier(max_depth=i, splitter=\"random\")\n",
    "    \n",
    "    #cfl_entropy = arbol de desicion con metodo de ramificacion ganancia de informacion\n",
    "        #criterion = medida de selección de atributo\n",
    "        #max_dep = profundidad maxima del arbol\n",
    "    clf_entropy = DecisionTreeClassifier(max_depth=i, criterion=\"entropy\")\n",
    "    \n",
    "    #cfl_entropy_rand = arbol de desicion con metodo de ramificacion ganancia de informacion y usando division aleatoria\n",
    "        #max_dep = profundidad maxima del arbol\n",
    "        #splitter = estrategia de division\n",
    "        #criterion = medida de selección de atributo\n",
    "    clf_entropy_rand = DecisionTreeClassifier(max_depth=i, splitter=\"random\", criterion=\"entropy\")\n",
    "    \n",
    "    #Entrenamiento de los arboles\n",
    "    clf_gini.fit(x_t,y_t)\n",
    "    clf_gini_rand.fit(x_t,y_t)\n",
    "    clf_entropy.fit(x_t,y_t)\n",
    "    clf_entropy_rand.fit(x_t,y_t)\n",
    "    \n",
    "    #Taza de aciertos calculada usando el conjunto de validacion\n",
    "    print(\"Arbol de decision con GINI y mejor division: \"+str(clf_gini.score(val_x,val_y)))\n",
    "    print(\"Arbol de decision con GINI y division aleatoria: \"+str(clf_gini_rand.score(val_x,val_y)))\n",
    "    print(\"Arbol de decision con Ganancia de informacion y mejor division: \"+str(clf_entropy.score(val_x,val_y)))\n",
    "    print(\"Arbol de decision con Ganancia de informacion y division aleatoria: \"+str(clf_entropy_rand.score(val_x,val_y)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de haber realizado las distintas podas con ambos métodos de ramificación. Se puede concluir que, usando una profundidad máxima de 8 atributos, GINI como método de ramificación y método de división de la mejor opción. Presentan una mayor taza que los demás árboles. Teniendo estos valores definidos, crearemos el clasificador con el conjunto de entrenamiento completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8)\n",
    "\n",
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90     12324\n",
      "           1       0.55      0.75      0.64      2736\n",
      "\n",
      "    accuracy                           0.84     15060\n",
      "   macro avg       0.75      0.81      0.77     15060\n",
      "weighted avg       0.87      0.84      0.85     15060\n",
      "\n",
      "Accuracy score:  0.8442231075697211\n",
      "Confusion matrix:\n",
      "\n",
      "[[10669   691]\n",
      " [ 1655  2045]]\n"
     ]
    }
   ],
   "source": [
    "w = test.loc[:,14]\n",
    "z = test.drop(14, axis=1)\n",
    "pred = clf.predict(z)\n",
    "print(classification_report(pred,w))\n",
    "print(\"Accuracy score: \",accuracy_score(w,pred))\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(confusion_matrix(w,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los resultados\n",
    "El conjunto 0 equivale a la población que genera menos de 50k y el conjunto 1 a la población que gana más de 50k. El acccuracy score es el cálculo de los elementos que fueron catalogados de manera correcta como positivos y de manera correcta como negativos sobre el conjunto total de datos. En el árbol generado se pudo obtener un accuracy score con una probabilidad del 0.84, lo cual es una probabilidad bastante alta he indica que el modelo clasifica bien.\n",
    "Precision se encarga de calcular los elementos que son positivos quedaron bien catalogados, \"cuánto es correcto del modelo cuando dice que es correcto\". Para el conjunto 0 se obtuvo un valor del 0.94, lo cual es un valor muy bueno y quiere decir que la mayoría de las veces va a quedar bien clasificado una persona que gana menos de 50k. Para el conjunto 1 se obtuvo un valor del 0.55, lo cual es un valor medio, lo que equivale a decir que la mitad de las veces va a quedar bien clasificado una persona que gana más de 50k.\n",
    "El recall se encarga de calcular cuántos de los positivos reales captura nuestro modelo al etiquetarlo como positivo, \"de los que realmente se debían clasificar, cuantos se clasificaron\". Para el conjunto 0 de los que debían haberse clasificado bien el 87% quedó bien clasificado y para el conjunto 1, el 77% quedó bien clasificado.\n",
    "El f1-score es una mezcla de precision y recall, ya que sirve para evaluar el balance que hay entre precision y recall. Lo cual para el conjunto 0 tiene un alto grado de precision con 0.90 y el conjunto 1 no tanto, ya que tiene 0.64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máquina de vectores de soporte\n",
    "La librería skleanr posee varios tipos de algoritmos para implementar el aprendizaje por maquinita de vectores de soporte, los que vamos a usar son:\n",
    "* **SVC**: C-Clasificación de vectores de soporte. La implementación se basa en libsvm. El tiempo de ajuste se escala al menos cuadráticamente con el número de muestras y puede ser poco práctico más allá de decenas de miles de muestras. Para conjuntos de datos grandes. El soporte multiclase se maneja de acuerdo con un esquema uno contra uno.\n",
    "* **LinearSVC**: Similar a SVC con el parámetro kernel = 'linear', pero implementado en términos de liblinear en lugar de libsvm, por lo que tiene más flexibilidad en la elección de penalizaciones y funciones de pérdida y debería escalar mejor a grandes cantidades de muestras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación lineal\n",
    "\n",
    "**C**: Cuando más se aproxima C a cero, menos se penalizan los errores y más observaciones pueden estar en el lado incorrecto del margen o incluso del hiperplano. C es a fin de cuentas el hiperparámetro encargado de controlar el balance entre bias y varianza del modelo. Los valores de C a probar son: 0.1, 1, 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   *0.39343718926085514 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=0.1,class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"   *\"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   *0.7683128936029168 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=1,class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"   *\"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   *0.7593636062313557 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=10,class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"   *\"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre más aumentamos el valor de C; castigo de la penalización. Mayor es la taza de error al clasificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separecion radial\n",
    "Los parámetros que debemos estimar son los siguientes:\n",
    "\n",
    "* **C**: Cuando más se aproxima C a cero, menos se penalizan los errores y más observaciones pueden estar en el lado incorrecto del margen o incluso del hiperplano. C es a fin de cuentas el hiperparámetro encargado de controlar el balance entre bias y varianza del modelo.\n",
    "* **kernel**: La función principal del núcleo es transformar los datos de entrada del conjunto de datos dado en la forma requerida. Existen varios tipos de funciones, como la función de base lineal, polinómica y radial (RBF). \n",
    "* **Gamma**: Parámetro de regularización en el parámetro Scikit-learn C de Python utilizado para mantener la regularización. Aquí C es el parámetro de penalización, que representa la clasificación errónea o el término de error. El término de clasificación errónea o error le dice a la optimización SVM cuánto error es soportable. Así es como puede controlar la compensación entre el límite de decisión y el término de clasificación errónea. Un valor menor de C crea un hiperplano de margen pequeño y un valor mayor de C crea un hiperplano de margen mayor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =0.1: 0.24560822008617833\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=0.1, gamma=0.1, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =0.1: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =1: 0.24560822008617833\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=0.1, gamma=1, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =1: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =10: 0.24560822008617833\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=0.1, gamma=10, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =10: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =0.1: 0.7570434206165064\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=0.5, gamma=0.1, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =0.1: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =1: 0.7543917799138217\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=0.5, gamma=1, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =1: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =10: 0.7543917799138217\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=0.5, gamma=10, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =10: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =0.1: 0.7570434206165064\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=1, gamma=0.1, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =0.1: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =0.1: 0.7550546900894929\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=1, gamma=1, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =0.1: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =0.1: 0.7543917799138217\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=1, gamma=10, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =0.1: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =0.1: 0.7570434206165064\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=10, gamma=0.1, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =0.1: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =0.1: 0.7550546900894929\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=10, gamma=1, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =0.1: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMV RBF con C=0.1 gamma =0.1: 0.7543917799138217\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=10, gamma=10, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"SMV RBF con C=0.1 gamma =0.1: \"+str(clf.score(val_x,val_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separacion polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=1000: 0.24560822008617833 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly', C=0.1, degree=1000, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"degree=1000: \"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=10000: 0.24560822008617833 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly', C=0.1, degree=10000, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"degree=10000: \"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=100000: 0.24560822008617833 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly', C=0.1, degree=100000, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"degree=100000: \"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=1000: 0.24560822008617833 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly', C=1, degree=1000, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"degree=1000: \"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=10000: 0.24560822008617833 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly', C=1, degree=10000, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"degree=10000: \"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=100000: 0.24560822008617833 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly', C=1, degree=100000, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"degree=100000: \"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=1000: 0.24560822008617833 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly', C=10, degree=1000, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"degree=1000: \"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=10000: 0.24560822008617833 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly', C=10, degree=10000, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"degree=10000: \"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=100000: 0.24560822008617833 Accuracy score\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly', C=10, degree=100000, class_weight=\"balanced\")\n",
    "clf = clf.fit(x_t,y_t)\n",
    "print(\"degree=100000: \"+str(clf.score(val_x,val_y))+\" Accuracy score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de haber realizado el entrenamiento con los distintos parámetros que pueden ser ingresados para obtener el mejor clasificadora, se puede determinar que la máquina de vectores de soporte con separación lineal y un valor de 10 para C; la cual indica la penalización al error. Da los mejores resultados.\n",
    "\n",
    "Procedemos a realizar el entrenamiento con el conjunto de entrenamiento completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87     14659\n",
      "           1       0.09      0.86      0.17       401\n",
      "\n",
      "    accuracy                           0.77     15060\n",
      "   macro avg       0.54      0.82      0.52     15060\n",
      "weighted avg       0.97      0.77      0.85     15060\n",
      "\n",
      "Accuracy score:  0.7735059760956176\n",
      "Confusion matrix:\n",
      "\n",
      "[[11304    56]\n",
      " [ 3355   345]]\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=10,class_weight=\"balanced\")\n",
    "clf = clf.fit(x,y)\n",
    "w = test.loc[:,14]\n",
    "z = test.drop(14, axis=1)\n",
    "pred = clf.predict(z)\n",
    "print(classification_report(pred,w))\n",
    "print(\"Accuracy score: \",accuracy_score(w,pred))\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(confusion_matrix(w,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar el entrenamiento con el conjunto de datos de entrenamiento, logró aumentar el accuracy de 0.75 a 0.77, lo cual ayuda a disminuir el error y se puede concluir que la máquina de vectores de soporte logra clasificar bien los conjuntos.\n",
    "\n",
    "La precision para las personas que ganan menos de 50k logro dar el resultado máximo, por lo tanto, el clasificador puede identificar a la perfección cuando una persona gana menos de 50k y cuando una persona no gana más de 50k. Para el conjunto 1 dio un valor de 0.09 lo cual es un valor bastante bajo, ya que, si el clasificador lo hiciera al azar, obtendría mejores resultados. Esto se debe por el desbalanceo de las clases.\n",
    "\n",
    "El recall obtenido por el conjunto 0 de 0.77. Lo cual indica que de los que están clasificados como verdaderos el 77% está bien clasificado. Para el conjunto 1 su recall fue de 0.86, lo cual es una muy buena clasificación. Esto debería ser gracias a la poca cantidad de datos.\n",
    "\n",
    "# Conclusión\n",
    "Antes de poder realizar la evaluación entre los métodos de entrenamiento, se necesitó hacerle un tratamiento a los datos donde se incluía la tarea de buscar los datos atípicos, lo cual se realizó solo sobre los datos numéricos continuos que ya venían establecidos por la base de datos.\n",
    "\n",
    "Después de realizar el entrenamiento y validación de los parámetros para el método de árbol de decisión, se logró encontrar que haciendo una poda con los 8 atributos más significativos de los 14 disponibles, lograba dar el mejor desempeño de todos los árboles desarrollados.\n",
    "\n",
    "Para la máquina de vectores de soporte durante el entrenamiento y la validación. Se logró encontrar que realizar una división lineal con una penalización C de 10 lograba dar los mejores resultados\n",
    "\n",
    "Si comparamos la técnica de árboles de decisión y máquina de vectores de soporte con el fin de evaluar cual realiza una mejor clasificación de las personas que ganan menos de 50k y 50k o más. Se puede decir que el árbol de decisión tiene una mayor taza de aciertos debido a que 84% de las veces logra clasificar bien. Se puede resaltar el Recall obtenido por la máquina de vectores de soporte al clasificar las personas que ganan 50k o más con un valor del 86%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentarios:\n",
    "Bien hecha la estimación de parámetros, es importante explorar valores en un rango más amplio. El análisis de los resultados de la máquina de soporte no es correcto, en la tabla de confusión se ve que aprendió mal la segunda clase.\n",
    "\n",
    "Calificación:\n",
    "Preparación de los datos: 4,5\n",
    "Estimación de parámetros: 5\n",
    "Entrenamiento y prueba: 4,5\n",
    "Análisis de resultados: 3,5\n",
    "Informe: 5,0\n",
    "Sustentación: 0,0\n",
    "Nota total: 3,9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
